{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report-hw6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iciODdQ4dMfU"
      },
      "source": [
        "#Token Ring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyNrfYyXdw7e"
      },
      "source": [
        "##Постановка задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACDIVGpad2Vd"
      },
      "source": [
        "Задача: Построение простой модели сетевого протокола TokenRing и исследовании его свойств\n",
        "\n",
        "Этапы:\n",
        "+ Реализовать модель протокола\n",
        "+ Исследовать пропускную способность сети (throughput) и характерное время задержки (latency) в зависимости от количества узлов N и количества пакетов P\n",
        "+ Проанализировать полученные результаты\n",
        "+ Оптимизировать throughput или latency и исследовать влияние оптимизаций для одного режима на весь спектр режимов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uNO5TQ8f2r2"
      },
      "source": [
        "## Определения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGU_W_jq-2op"
      },
      "source": [
        "+ Характерное время задержки (latency) - промежуток времени с момента отправки токена с ноды-отправителя до момента получения на ноде-получателе. \n",
        "\n",
        "+ Пропускную способность сети (throughput) - количество токенов прошедших через ноду за единицу времени.\n",
        "\n",
        "+ Максимальное количество токенов в системе - размер очереди * количество нод (нод коннекторов), то есть совокупный размер очередей.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMXavTVgfrLj"
      },
      "source": [
        "## Реализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVZon-Y-dVD2"
      },
      "source": [
        "Протокол реализован на взаимодействии Node через NodeConnector, представляющий из себя блокирующую очередь (java.util.concurrent).\n",
        "Ноды передают далее по кругу пакет - токен, содержащий id и вспомогательное поле за замера времени задержки.\n",
        "\n",
        "При получении токена - нода его обрабатывает и передаёт дальше, не выбрасывая из системы.\n",
        "\n",
        "На всех нодах кроме одной пустые консьюмеры, нулевая же обрабатывает токен и получает.\n",
        "\n",
        "Ноды запускаются в разных потоках.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfRWWvVqgCPy"
      },
      "source": [
        "## Описание эспериментальной установки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F338FNKduns"
      },
      "source": [
        "Ноутбук DELL:\n",
        "+ Intel® Core™ i5-8300H CPU @ 2.30GHz × 8 \n",
        "+ RAM: 8Gb DDR3\n",
        "+ OS: Ubuntu 20.04.2 LTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLm6OCRyJpSC"
      },
      "source": [
        "## Постановка эксперимента"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNlT64HbJvcN"
      },
      "source": [
        "Эксперимент проводится с помощью библиотеки для модульного тестирования Junit. \n",
        "\n",
        "Предварительно проводится \"прогрев кода\" - работа протокола на 2х нода с 2мя токенами в течение 5 секунд.\n",
        "\n",
        "Для latency - единицы измерения nanoseconds. Время замеряется с помощью System.nanotime().\n",
        "\n",
        "Для throughput - единицы измерения количество токенов прошедших за 0.5 секунды.\n",
        "\n",
        "Как сказано выше, для замера latency и throughput используется только одна нода, соответственно все замеры - это значение за полный круг. \n",
        "\n",
        "Мы можем не считывать данные со всех нод, так как все сообщения проходят в определнном порядке, который не нарушится никогда, соответственно, если какой-то токен задержится на какой-то ноде, то он задержится и при прохождении всего круга."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ylW9nIe_Si1"
      },
      "source": [
        "## Определение максимального количества нод для сбора данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkpUmhHsKlpk"
      },
      "source": [
        "Проведём эксперимент по определению количества нод, доступных для проведения честного эксперимента - максимальное возможное количество потоков, которое мы можем использовать в эксперименте без потери валидности результатов.\n",
        "\n",
        "Для этого запустим протокол на разном количестве нод."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHlAKo7DaG1u"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1lem9aaQ_yon7vFOOt__8J7LBFsEZsRAS) ![](https://drive.google.com/uc?export=view&id=1--qKRrUbX9I9tPh3JMz8dgmG3mnZlBOQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWLgL51_bZbc"
      },
      "source": [
        "Заметим, что на количестве нод 5, 6, 7 появляется больший разброс по данным, это связано с тем, что в некторые моменты управление процессами передается системным приложениям.\n",
        "\n",
        "В дальнейшем будем исследовать только 2, 3, 4 ноды."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBfQdlcHcFzl"
      },
      "source": [
        "## Определение зависимости latency и throughput от размера очереди."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKJ7704chzr"
      },
      "source": [
        "Далее представлены зависимости latency и throughput от размера очереди при разном количестве токенов в системе (нагрузке на систему).\n",
        "\n",
        "Размер очереди варируется от 2 до количества нод + 2.\n",
        "Рассматриваем три варианта нагрузки.\n",
        "\n",
        "Low load - количество токенов равно половине количества нод.\n",
        "\n",
        "Medium load - количество токенов равно количестве нод.\n",
        "\n",
        "High load - количество токенов равно 0.8 от 2 * количество нод.\n",
        "То есть больше количества нод и меньше макисмального количества, так же подходит для любого количества нод с очередью размера 2 и более."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbQ7e3t3chwp"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1-1dlgCODq4jgYzPKfWugvHsiHh0QulEr)![](https://drive.google.com/uc?export=view&id=1-9n1VTP394Il0jxEnR_VsgAiWllfeihs)![](https://drive.google.com/uc?export=view&id=1-JfvyJpjxOPUvm7i-0xYEYWBVTU5mldf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXHOYzDJkaIF"
      },
      "source": [
        "С увеличение количества нод увеличивается latency, что теоретически объяснимо - для прохождения полного круга необходимо пройти больше нод.\n",
        "\n",
        "На первых двух графиках почти нет заметных изменений в latency, увеличение очереди не даёт ускорения, так как количество токенов меньше количества нод, и все токены успевают обработаться без ожидания в очереди.\n",
        "\n",
        "Заметно небольшое увеличение только для 3 нод при размере очереди 2.\n",
        "\n",
        "А уже при высокой нагрузке заметно, что при малых размерах очереди увеличилось latency, образуя монотонную обратную зависимость. (Теперь не все токены обрабатываются без ожидания в очереди.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu_kSeR6chtw"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1-NYryDl3EB0rB5sgo08PsnLdIOvLPu7h)![](https://drive.google.com/uc?export=view&id=1-Ns9qdc9vATh3ha4c5kw6UJPJtKBeuUu)![](https://drive.google.com/uc?export=view&id=1-Svb0PsKPxeUCaA0c-OY06SS8ou7be53)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQjBwGY8chqs"
      },
      "source": [
        "Аналогичную картину мы можем наблюдать и с throughput.\n",
        "Изменения появляются в основном при повышенной нагрузке, всё по тем же причинам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkAUmC22chm0"
      },
      "source": [
        "Важно заметить, что обработка токенов не занимает много времени, поэтому мы получаем такие результаты на малой и средней нагрузках."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRnHjvpechey"
      },
      "source": [
        "Далее следует более детально изучить зависимость latency и throughput от количества токенов в системе при разных размемрах очереди."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWYhre1xUrDR"
      },
      "source": [
        "## Определение зависимости latency и throughput от размера очереди для 4х нод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "speyrqYiUq_2"
      },
      "source": [
        "Для этого рассмотрим только один вариант системы с 4 нодами.\n",
        "Проведём эксперимент для размеров очереди 4, 8, 12 с количеством токенов от 3 до максимального с шагом 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNkmKONTUq9h"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1zwrmmAfteywZSAnk1trP37l6lMyA9gut)![](https://drive.google.com/uc?export=view&id=1-7AO3M_l5jPoWA0dwujfup5JoLPl3jgT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im93hyJkUq7O"
      },
      "source": [
        "По графикам видно, что предположение о эффективности увеличения размера очереди подтвердилось и в этом эксперименте. \n",
        "Для одинакового кол-ва токенов latency при большем размере очереди в разы меньше.\n",
        "\n",
        "Аналогично и для throughput.\n",
        "\n",
        "Так важно заметить существование оптимального количества токенов в системе для throughput. Которое примерно равно половине максимальной нагрузке, что соответствует заполнености очередей наполовину в среднем. Из-за чего, вероятнее всего, и получается максимум - две соседние ноды смогут обработать весь пулл токенов без торможения остальных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGUmBvehu2i8"
      },
      "source": [
        "Проведём дополнительный эксперимент для подтверждения предыдущего и поиска верхрней границы throughput."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAiIQG75Uq4u"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1-BdrzjCq6urdHKiglzdmLpef98f9d7JP)![](https://drive.google.com/uc?export=view&id=1-AkCA-5Hu-2KFz1SJWKI7EN7JU1Iav4Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDddXgvoUq2h"
      },
      "source": [
        "Характер зависимостей остался таким же.\n",
        "\n",
        "Так же диапозон оптимальных значений для throughput увеличился, стал более пологим. То есть стал более близок к некой ассимптотической кривой.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3t_iWOpUqz9"
      },
      "source": [
        "## Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phCrX9RKUqxg"
      },
      "source": [
        "Задача: Построение простой модели сетевого протокола TokenRing и исследовании его свойств\n",
        "\n",
        "Этапы:\n",
        "В данной работе реализована модель протокола, исследованы throughput и latency в зависимости от количества нод и количества токенов, проанализированы полученные результаты\n",
        "\n",
        "В результате, получены выводы, что latency прямо пропорциональнно зависит от размера очередей. Благодаря уменьшению времени ожидания нод на передачу токена следующей ноде.\n",
        "\n",
        "Так же выявлено существование некого оптимального диапозона количества токенов в системе в зависимости от размера очередей, равного половине макисмального количества токенов. Это может быть практически использовано в определении размера очередей для конкретной системы, с известными средними нагрузками в ней."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7KQ5Q1LypxH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}